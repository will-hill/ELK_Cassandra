{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='imgs/logstash.png' width='750'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# c* + elk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "elastic_version = '6.6.2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# c* jdbc driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "verify location:\n",
      "-rw-r--r--  1 Bhill  staff  7645422 Apr 24 10:06 logstash_vol/cassandra-jdbc-driver-1.3.jar\n",
      "\n",
      "verify class name:\n",
      "  6211 Mon Feb 11 15:37:56 EST 2019 com/dbschema/CassandraJdbcDriver.class\n"
     ]
    }
   ],
   "source": [
    "!echo 'verify location:'\n",
    "!ls -l   logstash_vol/cassandra-jdbc-driver-1.3.jar\n",
    "\n",
    "!echo\n",
    "!echo 'verify class name:'\n",
    "!jar tvf logstash_vol/cassandra-jdbc-driver-1.3.jar | grep CassandraJdbcDriver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# logstash config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__the lack of cron schedule indicates this will run and quit__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input {\r\n",
      "  jdbc {\r\n",
      "    jdbc_driver_library    => \"/config-dir/cassandra-jdbc-driver-1.3.jar\"\r\n",
      "    jdbc_driver_class      => \"com.dbschema.CassandraJdbcDriver\"\r\n",
      "    jdbc_connection_string => \"jdbc:cassandra://cassandra:9042/elk_c\"\r\n",
      "    jdbc_user              => \"root\"\r\n",
      "    statement              => \"select id, city, name, phone, salary from employee\"\r\n",
      "  }\r\n",
      "}\r\n",
      "output {  \r\n",
      "    elasticsearch {  \r\n",
      "\thosts => [\"elasticsearch:9200\"]  \r\n",
      "\tindex => \"employees\"\r\n",
      "    }  \r\n",
      "}  \r\n"
     ]
    }
   ],
   "source": [
    "!cat logstash_vol/logstash.cassandra.conf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bulk load & quit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending Logstash logs to /usr/share/logstash/logs which is now configured via log4j2.properties\n",
      "[2019-04-24T17:54:11,689][INFO ][logstash.setting.writabledirectory] Creating directory {:setting=>\"path.queue\", :path=>\"/usr/share/logstash/data/queue\"}\n",
      "[2019-04-24T17:54:11,702][INFO ][logstash.setting.writabledirectory] Creating directory {:setting=>\"path.dead_letter_queue\", :path=>\"/usr/share/logstash/data/dead_letter_queue\"}\n",
      "[2019-04-24T17:54:12,371][WARN ][logstash.config.source.multilocal] Ignoring the 'pipelines.yml' file because modules or command line options are specified\n",
      "[2019-04-24T17:54:12,392][INFO ][logstash.runner          ] Starting Logstash {\"logstash.version\"=>\"6.6.2\"}\n",
      "[2019-04-24T17:54:12,444][INFO ][logstash.agent           ] No persistent UUID file found. Generating new UUID {:uuid=>\"16a5e62f-45a1-4672-a441-9e2bf459cf63\", :path=>\"/usr/share/logstash/data/uuid\"}\n",
      "[2019-04-24T17:54:13,440][WARN ][logstash.monitoringextension.pipelineregisterhook] xpack.monitoring.enabled has not been defined, but found elasticsearch configuration. Please explicitly set `xpack.monitoring.enabled: true` in logstash.yml\n",
      "[2019-04-24T17:54:14,774][INFO ][logstash.licensechecker.licensereader] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://elasticsearch:9200/]}}\n",
      "[2019-04-24T17:54:15,163][WARN ][logstash.licensechecker.licensereader] Restored connection to ES instance {:url=>\"http://elasticsearch:9200/\"}\n",
      "[2019-04-24T17:54:15,255][INFO ][logstash.licensechecker.licensereader] ES Output version determined {:es_version=>6}\n",
      "[2019-04-24T17:54:15,261][WARN ][logstash.licensechecker.licensereader] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}\n",
      "[2019-04-24T17:54:15,468][INFO ][logstash.monitoring.internalpipelinesource] Monitoring License OK\n",
      "[2019-04-24T17:54:15,472][INFO ][logstash.monitoring.internalpipelinesource] Validated license for monitoring. Enabling monitoring pipeline.\n",
      "[2019-04-24T17:54:20,533][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>\"main\", \"pipeline.workers\"=>10, \"pipeline.batch.size\"=>125, \"pipeline.batch.delay\"=>50}\n",
      "[2019-04-24T17:54:20,621][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://elasticsearch:9200/]}}\n",
      "[2019-04-24T17:54:20,647][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>\"http://elasticsearch:9200/\"}\n",
      "[2019-04-24T17:54:20,656][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>6}\n",
      "[2019-04-24T17:54:20,656][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}\n",
      "[2019-04-24T17:54:20,681][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>\"LogStash::Outputs::ElasticSearch\", :hosts=>[\"//elasticsearch:9200\"]}\n",
      "[2019-04-24T17:54:20,697][INFO ][logstash.outputs.elasticsearch] Using mapping template from {:path=>nil}\n",
      "[2019-04-24T17:54:20,720][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=>{\"template\"=>\"logstash-*\", \"version\"=>60001, \"settings\"=>{\"index.refresh_interval\"=>\"5s\"}, \"mappings\"=>{\"_default_\"=>{\"dynamic_templates\"=>[{\"message_field\"=>{\"path_match\"=>\"message\", \"match_mapping_type\"=>\"string\", \"mapping\"=>{\"type\"=>\"text\", \"norms\"=>false}}}, {\"string_fields\"=>{\"match\"=>\"*\", \"match_mapping_type\"=>\"string\", \"mapping\"=>{\"type\"=>\"text\", \"norms\"=>false, \"fields\"=>{\"keyword\"=>{\"type\"=>\"keyword\", \"ignore_above\"=>256}}}}}], \"properties\"=>{\"@timestamp\"=>{\"type\"=>\"date\"}, \"@version\"=>{\"type\"=>\"keyword\"}, \"geoip\"=>{\"dynamic\"=>true, \"properties\"=>{\"ip\"=>{\"type\"=>\"ip\"}, \"location\"=>{\"type\"=>\"geo_point\"}, \"latitude\"=>{\"type\"=>\"half_float\"}, \"longitude\"=>{\"type\"=>\"half_float\"}}}}}}}}\n",
      "[2019-04-24T17:54:20,996][INFO ][logstash.pipeline        ] Pipeline started successfully {:pipeline_id=>\"main\", :thread=>\"#<Thread:0x7b823337 run>\"}\n",
      "[2019-04-24T17:54:21,087][INFO ][logstash.agent           ] Pipelines running {:count=>1, :running_pipelines=>[:main], :non_running_pipelines=>[]}\n",
      "[2019-04-24T17:54:21,695][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting \"document_type\" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=>\"document_type\", :plugin=><LogStash::Outputs::ElasticSearch bulk_path=>\"/_xpack/monitoring/_bulk?system_id=logstash&system_api_version=2&interval=1s\", hosts=>[http://elasticsearch:9200], sniffing=>false, manage_template=>false, id=>\"51f66c9ec66feb8fd59be1157c335c1ddc5fb856d2b248254ae6add289cea7b7\", document_type=>\"%{[@metadata][document_type]}\", enable_metric=>true, codec=><LogStash::Codecs::Plain id=>\"plain_74c3a7f6-5c5f-4e19-b702-a8de6483328b\", enable_metric=>true, charset=>\"UTF-8\">, workers=>1, template_name=>\"logstash\", template_overwrite=>false, doc_as_upsert=>false, script_type=>\"inline\", script_lang=>\"painless\", script_var_name=>\"event\", scripted_upsert=>false, retry_initial_interval=>2, retry_max_interval=>64, retry_on_conflict=>1, ilm_enabled=>false, ilm_rollover_alias=>\"logstash\", ilm_pattern=>\"{now/d}-000001\", ilm_policy=>\"logstash-policy\", action=>\"index\", ssl_certificate_verification=>true, sniffing_delay=>5, timeout=>60, pool_max=>1000, pool_max_per_route=>100, resurrect_delay=>5, validate_after_inactivity=>10000, http_compression=>false>}\n",
      "[2019-04-24T17:54:21,712][INFO ][logstash.pipeline        ] Starting pipeline {:pipeline_id=>\".monitoring-logstash\", \"pipeline.workers\"=>1, \"pipeline.batch.size\"=>2, \"pipeline.batch.delay\"=>50}\n",
      "[2019-04-24T17:54:21,762][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=>{:removed=>[], :added=>[http://elasticsearch:9200/]}}\n",
      "[2019-04-24T17:54:21,777][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=>\"http://elasticsearch:9200/\"}\n",
      "[2019-04-24T17:54:21,791][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=>6}\n",
      "[2019-04-24T17:54:21,792][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=>6}\n",
      "[2019-04-24T17:54:21,807][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=>\"LogStash::Outputs::ElasticSearch\", :hosts=>[\"http://elasticsearch:9200\"]}\n",
      "[2019-04-24T17:54:21,883][INFO ][logstash.pipeline        ] Pipeline started successfully {:pipeline_id=>\".monitoring-logstash\", :thread=>\"#<Thread:0x2eee3e11 sleep>\"}\n",
      "[2019-04-24T17:54:21,895][INFO ][logstash.agent           ] Pipelines running {:count=>2, :running_pipelines=>[:main, :\".monitoring-logstash\"], :non_running_pipelines=>[]}\n",
      "[2019-04-24T17:54:22,286][INFO ][com.datastax.driver.core ] DataStax Java driver 3.6.0 for Apache Cassandra\n",
      "[2019-04-24T17:54:22,298][INFO ][com.datastax.driver.core.GuavaCompatibility] Detected Guava >= 19 in the classpath, using modern compatibility layer\n",
      "Apr 24, 2019 5:54:22 PM com.dbschema.CassandraClientURI createCluster\n",
      "INFO: sslenabled: false\n",
      "[2019-04-24T17:54:22,357][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}\n",
      "[2019-04-24T17:54:22,379][INFO ][com.datastax.driver.core.ClockFactory] Using native clock to generate timestamps.\n",
      "[2019-04-24T17:54:22,554][WARN ][com.datastax.driver.core.CodecRegistry] Ignoring codec FloatCodec [double <-> java.lang.Long] because it collides with previously registered codec DoubleCodec [double <-> java.lang.Long]\n",
      "[2019-04-24T17:54:22,689][INFO ][com.datastax.driver.core.NettyUtil] Did not find Netty's native epoll transport in the classpath, defaulting to NIO.\n",
      "[2019-04-24T17:54:23,417][WARN ][com.datastax.driver.core.ReplicationStrategy$NetworkTopologyStrategy] Error while computing token map for keyspace elk_c with datacenter datacenter1: could not achieve replication factor 2 (found 1 replicas only), check your keyspace replication settings.\n",
      "[2019-04-24T17:54:23,420][INFO ][com.datastax.driver.core.policies.DCAwareRoundRobinPolicy] Using data-center name 'datacenter1' for DCAwareRoundRobinPolicy (if this is incorrect, please provide the correct datacenter name with DCAwareRoundRobinPolicy constructor)\n",
      "[2019-04-24T17:54:23,423][INFO ][com.datastax.driver.core.Cluster] New Cassandra host cassandra/172.17.0.4:9042 added\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2019-04-24T17:54:23,772][INFO ][logstash.inputs.jdbc     ] (0.027487s) select id, city, name, phone, salary from employee\n",
      "[2019-04-24T17:54:23,873][WARN ][logstash.inputs.jdbc     ] Exception when executing JDBC query {:exception=>#<Sequel::DatabaseError: Java::ComDatastaxDriverCoreExceptions::CodecNotFoundException: Codec not found for requested operation: [varint <-> java.lang.Integer]>}\n",
      "[2019-04-24T17:54:24,653][INFO ][logstash.pipeline        ] Pipeline has terminated {:pipeline_id=>\"main\", :thread=>\"#<Thread:0x7b823337 run>\"}\n",
      "[2019-04-24T17:54:26,780][INFO ][logstash.pipeline        ] Pipeline has terminated {:pipeline_id=>\".monitoring-logstash\", :thread=>\"#<Thread:0x2eee3e11 run>\"}\n"
     ]
    }
   ],
   "source": [
    "!docker run -h logstash                            \\\n",
    "            --name logstash                        \\\n",
    "            --link cassandra:cassandra             \\\n",
    "            --link elasticsearch:elasticsearch     \\\n",
    "            -it --rm                               \\\n",
    "            -v ${PWD}/logstash_vol:/config-dir     \\\n",
    "            logstash:6.6.2                         \\\n",
    "            -f /config-dir/logstash.cassandra.conf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kibana validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='imgs/kibana_timelion.png' width=450 />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "contents",
   "title_sidebar": "contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
